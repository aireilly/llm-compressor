# About llmcompressor

`llmcompressor` is an easy-to-use library for optimizing models for deployment with `vllm`, including:

* Comprehensive set of quantization algorithms for weight-only and activation quantization
* Seamless integration with Hugging Face models and repositories safetensors-based file format compatible with `vllm`
* Large model support via `accelerate`