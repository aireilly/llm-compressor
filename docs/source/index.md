# Getting started with llmcompressor

:::{figure} ./assets/logos/vllm-logo-text-light.png
:align: center
:alt: LLM Compressor
:class: no-scaled-link
:width: 60%
:::

:::{raw} html

<p style="text-align:center">
<script async defer src="https://buttons.github.io/buttons.js"></script>
<a class="github-button" href="https://github.com/vllm-project/llm-compressor" data-show-count="true" data-size="large" aria-label="Star">Star</a>
<a class="github-button" href="https://github.com/vllm-project/llm-compressor/subscription" data-icon="octicon-eye" data-size="large" aria-label="Watch">Watch</a>
<a class="github-button" href="https://github.com/vllm-project/llm-compressor/fork" data-icon="octicon-repo-forked" data-size="large" aria-label="Fork">Fork</a>
</p>
:::

llmcompressor is a fast and easy-to-use library for compressing and optimizing LLM models.

## Documentation

% About llmcompressor
:::{toctree}
:maxdepth: 2

about.md

:::

% Installing llmcompressor
:::{toctree}
:maxdepth: 2

installing.md

:::

% Usage examples
:::{toctree}
:maxdepth: 1
:titlesonly:

examples.md

:::

% Inferencing with vLLM
:::{toctree}
:maxdepth: 2

inferencing-with-vllm.md

:::
